{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal_length    150 non-null float64\n",
      "sepal_width     150 non-null float64\n",
      "petal_length    150 non-null float64\n",
      "petal_width     150 non-null float64\n",
      "species         150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,:-1].values\n",
    "label = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To get the minimum score Threshold\n",
    "2. To understand what maximum score I can achieve from the dataset\n",
    "3. How to extract the best training and testing sample that can give the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide what can be the best and minimum accuracy score I can expect from the data using LogisticRegressiojn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Initialize the algo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.8       , 0.93333333, 1.        , 1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Perform Cross Validation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model,\n",
    "                        features,\n",
    "                        label,\n",
    "                        cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get the minimum score Threshold:  0.8\n",
      "To understand what maximum score I can achieve from the dataset:  1.0\n",
      "Average Score Expected:  0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"To get the minimum score Threshold: \",np.min(scores))\n",
    "print(\"To understand what maximum score I can achieve from the dataset: \",np.max(scores))\n",
    "print(\"Average Score Expected: \", np.average(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 1.0, train score: 0.9555555555555556, for Sample Split: 1\n",
      "Test Score: 1.0, train score: 0.9481481481481482, for Sample Split: 3\n",
      "Test Score: 1.0, train score: 0.9629629629629629, for Sample Split: 5\n",
      "Test Score: 1.0, train score: 0.9629629629629629, for Sample Split: 7\n",
      "Test Score: 1.0, train score: 0.9555555555555556, for Sample Split: 9\n"
     ]
    }
   ],
   "source": [
    "#How to extract the best training and testing sample that can give the best score\n",
    "# KFold Cross Validation\n",
    "\n",
    "#1. Initialize the algo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "#2. Initialize KFold Method\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n",
    "              random_state=1,\n",
    "              shuffle=True)\n",
    "\n",
    "#3. Initialize For Loop \n",
    "\n",
    "i=0\n",
    "for train,test in kfold.split(features):\n",
    "    i = i+1\n",
    "    X_train,X_test = features[train],features[test]\n",
    "    y_train,y_test = label[train],label[test]\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    if model.score(X_test,y_test) >= 0.95:\n",
    "        print(\"Test Score: {}, train score: {}, for Sample Split: {}\".format(model.score(X_test,y_test),model.score(X_train,y_train),i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hack -- To extract the sample\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n",
    "              random_state=1,\n",
    "              shuffle=True)\n",
    "i=0\n",
    "for train,test in kfold.split(features):\n",
    "    i = i+1\n",
    "    if i == 5:\n",
    "        X_train,X_test,y_train,y_test = features[train],features[test],label[train],label[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Model To Deploy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "finalModel = LogisticRegression()\n",
    "finalModel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9777777777777777, train score: 0.9523809523809523, for Sample Split: 1\n",
      "Test Score: 0.9555555555555556, train score: 0.9523809523809523, for Sample Split: 4\n",
      "Test Score: 0.9777777777777777, train score: 0.9523809523809523, for Sample Split: 5\n",
      "Test Score: 0.9777777777777777, train score: 0.9523809523809523, for Sample Split: 6\n",
      "Test Score: 0.9777777777777777, train score: 0.9619047619047619, for Sample Split: 7\n",
      "Test Score: 0.9777777777777777, train score: 0.9523809523809523, for Sample Split: 8\n"
     ]
    }
   ],
   "source": [
    "#StratifiedShuffleSplit\n",
    "#How to extract the best training and testing sample that can give the best score with control over test_size parameter\n",
    "# KFold Cross Validation\n",
    "\n",
    "#1. Initialize the algo\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "#2. Initialize StratifiedShuffleSplit Method\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "ss = StratifiedShuffleSplit(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n",
    "              random_state=1,\n",
    "              test_size=0.3)\n",
    "\n",
    "#3. Initialize For Loop \n",
    "\n",
    "i=0\n",
    "for train,test in ss.split(features,label):\n",
    "    i = i+1\n",
    "    X_train,X_test = features[train],features[test]\n",
    "    y_train,y_test = label[train],label[test]\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    if model.score(X_test,y_test) >= 0.95:\n",
    "        print(\"Test Score: {}, train score: {}, for Sample Split: {}\".format(model.score(X_test,y_test),model.score(X_train,y_train),i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hack -- To extract the sample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "ss = StratifiedShuffleSplit(n_splits=10, #n_splits should be equal to no of cv value in cross_val_score\n",
    "              random_state=1,\n",
    "              test_size=0.3)\n",
    "i=0\n",
    "for train,test in ss.split(features,label):\n",
    "    i = i+1\n",
    "    if i == 7:\n",
    "        X_train,X_test,y_train,y_test = features[train],features[test],label[train],label[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create final Deployable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use StratifiedShuffleSplit when you need to define the test_size for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 1.0 Train: 0.9619047619047619 RS: 3\n",
      "Test: 1.0 Train: 0.9619047619047619 RS: 9\n",
      "Test: 1.0 Train: 0.9523809523809523 RS: 19\n",
      "Test: 1.0 Train: 0.9523809523809523 RS: 23\n",
      "Test: 1.0 Train: 0.9619047619047619 RS: 33\n",
      "Test: 1.0 Train: 0.9523809523809523 RS: 39\n",
      "Test: 1.0 Train: 0.9428571428571428 RS: 44\n",
      "Test: 1.0 Train: 0.9619047619047619 RS: 65\n",
      "Test: 1.0 Train: 0.9619047619047619 RS: 68\n",
      "Test: 1.0 Train: 0.9428571428571428 RS: 100\n",
      "Test: 1.0 Train: 0.9523809523809523 RS: 107\n",
      "Test: 1.0 Train: 0.9619047619047619 RS: 120\n",
      "Test: 1.0 Train: 0.9428571428571428 RS: 131\n",
      "Test: 1.0 Train: 0.9523809523809523 RS: 140\n",
      "Test: 1.0 Train: 0.9428571428571428 RS: 143\n",
      "Test: 1.0 Train: 0.9428571428571428 RS: 144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "for i in range(1,151):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                    label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=i)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    if model.score(X_test,y_test) == 1:\n",
    "        print(\"Test: {} Train: {} RS: {}\".format(model.score(X_test,y_test),model.score(X_train,y_train),i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
